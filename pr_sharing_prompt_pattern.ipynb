{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956c67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc198df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Dell/Desktop/AI for Software Engineering/Project/Dataset\\snapshot_20230727\\20230727_195927_pr_sharings.json\n",
      "C:/Users/Dell/Desktop/AI for Software Engineering/Project/Dataset\\snapshot_20230803\\20230803_093947_pr_sharings.json\n",
      "C:/Users/Dell/Desktop/AI for Software Engineering/Project/Dataset\\snapshot_20230810\\20230810_123110_pr_sharings.json\n",
      "C:/Users/Dell/Desktop/AI for Software Engineering/Project/Dataset\\snapshot_20230817\\20230817_125147_pr_sharings.json\n",
      "C:/Users/Dell/Desktop/AI for Software Engineering/Project/Dataset\\snapshot_20230824\\20230824_100450_pr_sharings.json\n",
      "C:/Users/Dell/Desktop/AI for Software Engineering/Project/Dataset\\snapshot_20230831\\20230831_060603_pr_sharings.json\n",
      "C:/Users/Dell/Desktop/AI for Software Engineering/Project/Dataset\\snapshot_20230907\\20230907_091631_pr_sharings.json\n",
      "C:/Users/Dell/Desktop/AI for Software Engineering/Project/Dataset\\snapshot_20230914\\20230914_074826_pr_sharings.json\n",
      "C:/Users/Dell/Desktop/AI for Software Engineering/Project/Dataset\\snapshot_20231012\\20231012_233628_pr_sharings.json\n",
      "Total files read: 9\n"
     ]
    }
   ],
   "source": [
    "# Path pattern to locate all JSON files across snapshots\n",
    "file_pattern = \"C:/Users/Dell/Desktop/AI for Software Engineering/Project/Dataset/snapshot_*/*_pr_sharings.json\"\n",
    "\n",
    "# Initialize an empty list to store all JSON data\n",
    "all_data = []\n",
    "\n",
    "# Loop through all matching file paths and load each file\n",
    "for path in glob.glob(file_pattern):\n",
    "    print(path)\n",
    "    with open(path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "        all_data.append(data)\n",
    "\n",
    "# all_data now contains data from all JSON files\n",
    "print(f\"Total files read: {len(all_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca66d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list for rows that will form the DataFrame\n",
    "rows = []\n",
    "\n",
    "# Define the pattern analysis function\n",
    "def analyze_prompt_structure(data):\n",
    "    detected_patterns = []\n",
    "    \n",
    "    persona_keywords = [\"you are\", \"act as\", \"pretend to be\", \"pretend you are\"]\n",
    "    recipe_keywords = [\"step-by-step\", \"recipe\", \"guide\"]\n",
    "    template_keywords = [\"template\", \"formatting\"]\n",
    "    automator_keywords = [\"script\", \"code\", \"executable\"]\n",
    "    simple_instruction_keywords = [\"explain\", \"describe\", \"list\", \"tell me\", \"give me\"]\n",
    "    context_instruction_keywords = [\"based on\", \"with this information\"]\n",
    "    question_keywords = [\"what\", \"where\", \"when\", \"who\", \"why\"]\n",
    "\n",
    "    def contains_keywords(text, keywords):\n",
    "        return any(keyword in text.lower() for keyword in keywords)\n",
    "\n",
    "    for source in data.get(\"Sources\", []):\n",
    "        body = source.get(\"Body\", \"\")\n",
    "        created_at = source.get(\"CreatedAt\")\n",
    "        closed_at = source.get(\"ClosedAt\")\n",
    "        state = \"Closed\" if closed_at is not None else \"Open\"\n",
    "\n",
    "        time_lapsed = None\n",
    "        if created_at and closed_at:\n",
    "            created_at_dt = datetime.strptime(created_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            closed_at_dt = datetime.strptime(closed_at, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "            time_lapsed = closed_at_dt - created_at_dt\n",
    "\n",
    "        body_patterns = []\n",
    "\n",
    "        # Check for patterns in the body text\n",
    "        if contains_keywords(body, persona_keywords):\n",
    "            body_patterns.append(\"Persona Pattern\")\n",
    "        if contains_keywords(body, recipe_keywords):\n",
    "            body_patterns.append(\"Recipe Pattern\")\n",
    "        if contains_keywords(body, template_keywords):\n",
    "            body_patterns.append(\"Template Pattern\")\n",
    "        if contains_keywords(body, automator_keywords):\n",
    "            body_patterns.append(\"Output Automator Pattern\")\n",
    "        if contains_keywords(body, simple_instruction_keywords):\n",
    "            body_patterns.append(\"Simple Instruction Pattern\")\n",
    "        if contains_keywords(body, context_instruction_keywords):\n",
    "            body_patterns.append(\"Context and Instruction Pattern\")\n",
    "        if contains_keywords(body, question_keywords):\n",
    "            body_patterns.append(\"Question Pattern\")\n",
    "\n",
    "        conversations = source.get(\"ChatgptSharing\", [])\n",
    "        for item in conversations:\n",
    "            number_of_prompts = item.get(\"NumberOfPrompts\", \"N/A\")\n",
    "            conversation_url = item.get(\"URL\", \"N/A\")\n",
    "\n",
    "            for pattern in body_patterns:\n",
    "                detected_patterns.append((\n",
    "                    source['Number'],\n",
    "                    pattern,\n",
    "                    state,\n",
    "                    time_lapsed,\n",
    "                    number_of_prompts,\n",
    "                    conversation_url\n",
    "                ))\n",
    "\n",
    "    return detected_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93145724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each dictionary in all_data\n",
    "for data_dict in all_data:\n",
    "    # Check if 'Sources' key exists in each dictionary\n",
    "    if 'Sources' in data_dict:\n",
    "        for item in data_dict['Sources']:\n",
    "            if 'ChatgptSharing' in item:\n",
    "                for sharing in item['ChatgptSharing']:\n",
    "                    if 'Conversations' in sharing:\n",
    "                        for conversation in sharing['Conversations']:\n",
    "                            # Adding the fields to row\n",
    "                            row = {\n",
    "                                \"Type\": item.get('Type'),\n",
    "                                \"URL\": item.get('URL'),\n",
    "                                \"Author\": item.get('Author'),\n",
    "                                \"RepoName\": item.get('RepoName'),\n",
    "                                \"RepoLanguage\": item.get('RepoLanguage'),\n",
    "                                \"Number\": item.get('Number'),\n",
    "                                \"Title\": item.get('Title'),\n",
    "                                \"Body\": item.get('Body'),\n",
    "                                \"MergedAt\": item.get('MergedAt'),\n",
    "                                \"UpdatedAt\": item.get('UpdatedAt'),\n",
    "                                \"State\": item.get('State'),\n",
    "                                \"Additions\": item.get('Additions'),\n",
    "                                \"Deletions\": item.get('Deletions'),\n",
    "                                \"ChangedFiles\": item.get('ChangedFiles'),\n",
    "                                \"CommitsTotalCount\": item.get('CommitsTotalCount'),\n",
    "                                \"CSharing_URL\": sharing.get('URL'),\n",
    "                                \"CSharing_Status\": sharing.get('Status'),\n",
    "                                \"CSharing_DateOfConversation\": sharing.get('DateOfConversation'),\n",
    "                                \"CSharing_Title\": sharing.get('Title'),\n",
    "                                \"CSharing_NumberOfPrompts\": sharing.get('NumberOfPrompts'),\n",
    "                                \"CSharing_TokensOfPrompts\": sharing.get('TokensOfPrompts'),\n",
    "                                \"CSharing_TokensOfAnswers\": sharing.get('TokensOfAnswers'),\n",
    "                                \"Conversation_Prompt\": conversation.get('Prompt'),\n",
    "                                \"Conversation_Answer\": conversation.get('Answer')\n",
    "                            }\n",
    "                            rows.append(row)\n",
    "\n",
    "# Create DataFrame from rows\n",
    "df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa681e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect patterns for each source and add to the DataFrame\n",
    "detected_patterns = analyze_prompt_structure(data_dict)  # Use the last data_dict for patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610b02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a dictionary to store detected patterns for easy lookup\n",
    "pattern_dict = {}\n",
    "for number, pattern, state, time_lapsed, number_of_prompts, conversation_url in detected_patterns:\n",
    "    if number not in pattern_dict:\n",
    "        pattern_dict[number] = []\n",
    "    pattern_dict[number].append(pattern)\n",
    "\n",
    "# Add a new column for detected patterns\n",
    "df['Detected Patterns'] = df['Number'].map(lambda x: ', '.join(pattern_dict.get(x, [])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2753b03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of               Type                                                URL  \\\n",
       "0     pull request            https://github.com/labdao/plex/pull/469   \n",
       "1     pull request            https://github.com/labdao/plex/pull/469   \n",
       "2     pull request            https://github.com/labdao/plex/pull/469   \n",
       "3     pull request            https://github.com/labdao/plex/pull/469   \n",
       "4     pull request            https://github.com/labdao/plex/pull/469   \n",
       "...            ...                                                ...   \n",
       "7971  pull request          https://github.com/openai/evals/pull/1083   \n",
       "7972  pull request  https://github.com/VOICEVOX/voicevox_core/pull...   \n",
       "7973  pull request       https://github.com/MatrixAI/Polykey/pull/552   \n",
       "7974  pull request  https://github.com/VOICEVOX/voicevox_core/pull...   \n",
       "7975  pull request     https://github.com/VOICEVOX/voicevox/pull/1374   \n",
       "\n",
       "              Author                RepoName RepoLanguage  Number  \\\n",
       "0          AdamGoyer             labdao/plex           Go     469   \n",
       "1          AdamGoyer             labdao/plex           Go     469   \n",
       "2          AdamGoyer             labdao/plex           Go     469   \n",
       "3          AdamGoyer             labdao/plex           Go     469   \n",
       "4          AdamGoyer             labdao/plex           Go     469   \n",
       "...              ...                     ...          ...     ...   \n",
       "7971  AaronGoldsmith            openai/evals          C++    1083   \n",
       "7972          qryxip  VOICEVOX/voicevox_core          C++     532   \n",
       "7973    CMCDragonkai        MatrixAI/Polykey          C++     552   \n",
       "7974  sevenc-nanashi  VOICEVOX/voicevox_core          C++     538   \n",
       "7975       thiramisu       VOICEVOX/voicevox          C++    1374   \n",
       "\n",
       "                                                  Title  \\\n",
       "0                      add readme for openbabel to PLEX   \n",
       "1                      add readme for openbabel to PLEX   \n",
       "2                      add readme for openbabel to PLEX   \n",
       "3                      add readme for openbabel to PLEX   \n",
       "4                      add readme for openbabel to PLEX   \n",
       "...                                                 ...   \n",
       "7971                       [Eval] Viewport to grid size   \n",
       "7972                                        ドキュメントを刷新する   \n",
       "7973  Consolidating Configuration Entropy and Nodes ...   \n",
       "7974                  [vvm-async-api] Add: ユーザー辞書APIを追加   \n",
       "7975                                    コンテキストメニューのVue化   \n",
       "\n",
       "                                                   Body              MergedAt  \\\n",
       "0     The Chatgpt Thread used to create this pull re...                  None   \n",
       "1     The Chatgpt Thread used to create this pull re...                  None   \n",
       "2     The Chatgpt Thread used to create this pull re...                  None   \n",
       "3     The Chatgpt Thread used to create this pull re...                  None   \n",
       "4     The Chatgpt Thread used to create this pull re...                  None   \n",
       "...                                                 ...                   ...   \n",
       "7971  # Thank you for contributing an eval! ♥️\\r\\n\\r...  2023-07-04T02:05:57Z   \n",
       "7972  ## 内容\\r\\n\\r\\nRust/C/Python APIのドキュメントを刷新します。\\r...  2023-08-02T11:22:43Z   \n",
       "7973  ### Description\\r\\n\\r\\nThe configuration of Po...  2023-10-04T06:03:18Z   \n",
       "7974  ## 内容\\r\\n\\r\\nユーザー辞書を実装します。\\r\\n\\r\\n## 関連 Issue\\...  2023-07-22T14:01:36Z   \n",
       "7975  ## 内容\\r\\n\\r\\n<!--\\r\\nプルリクエストの内容説明を端的に記載してください。...  2023-07-22T22:56:59Z   \n",
       "\n",
       "                 UpdatedAt  ...  \\\n",
       "0     2023-07-05T03:30:59Z  ...   \n",
       "1     2023-07-05T03:30:59Z  ...   \n",
       "2     2023-07-05T03:30:59Z  ...   \n",
       "3     2023-07-05T03:30:59Z  ...   \n",
       "4     2023-07-05T03:30:59Z  ...   \n",
       "...                    ...  ...   \n",
       "7971  2023-07-04T17:23:30Z  ...   \n",
       "7972  2023-08-05T02:19:59Z  ...   \n",
       "7973  2023-10-04T06:29:40Z  ...   \n",
       "7974  2023-07-22T22:11:07Z  ...   \n",
       "7975  2023-07-22T23:59:28Z  ...   \n",
       "\n",
       "                                           CSharing_URL  CSharing_Status  \\\n",
       "0     https://chat.openai.com/share/8bd33825-e8c6-44...              200   \n",
       "1     https://chat.openai.com/share/8bd33825-e8c6-44...              200   \n",
       "2     https://chat.openai.com/share/8bd33825-e8c6-44...              200   \n",
       "3     https://chat.openai.com/share/8bd33825-e8c6-44...              200   \n",
       "4     https://chat.openai.com/share/8bd33825-e8c6-44...              200   \n",
       "...                                                 ...              ...   \n",
       "7971  https://chat.openai.com/share/4aeb8ed6-6dff-4f...              200   \n",
       "7972  https://chat.openai.com/share/60d93fac-6c72-45...              200   \n",
       "7973  https://chat.openai.com/share/5a302ea7-6134-40...              200   \n",
       "7974  https://chat.openai.com/share/54538577-b336-4b...              200   \n",
       "7975  https://chat.openai.com/share/96a908fa-3af7-4c...              200   \n",
       "\n",
       "      CSharing_DateOfConversation                       CSharing_Title  \\\n",
       "0                    July 5, 2023                   Open Babel on PLEX   \n",
       "1                    July 5, 2023                   Open Babel on PLEX   \n",
       "2                    July 5, 2023                   Open Babel on PLEX   \n",
       "3                    July 5, 2023                   Open Babel on PLEX   \n",
       "4                    July 5, 2023                   Open Babel on PLEX   \n",
       "...                           ...                                  ...   \n",
       "7971                 June 2, 2023  Understanding Grid Size Calculation   \n",
       "7972                July 15, 2023                                用語の選択   \n",
       "7973    Roger Qiu•August 21, 2023          Mutating Properties in Rust   \n",
       "7974                July 10, 2023                        Rustでのデフォルト関数   \n",
       "7975                July 17, 2023                    シンプルなコンテキストメニュー制御   \n",
       "\n",
       "      CSharing_NumberOfPrompts CSharing_TokensOfPrompts  \\\n",
       "0                            6                     2895   \n",
       "1                            6                     2895   \n",
       "2                            6                     2895   \n",
       "3                            6                     2895   \n",
       "4                            6                     2895   \n",
       "...                        ...                      ...   \n",
       "7971                        14                      581   \n",
       "7972                         1                      448   \n",
       "7973                         1                       57   \n",
       "7974                         1                      342   \n",
       "7975                         2                       92   \n",
       "\n",
       "      CSharing_TokensOfAnswers  \\\n",
       "0                         2311   \n",
       "1                         2311   \n",
       "2                         2311   \n",
       "3                         2311   \n",
       "4                         2311   \n",
       "...                        ...   \n",
       "7971                      2892   \n",
       "7972                       615   \n",
       "7973                       286   \n",
       "7974                       319   \n",
       "7975                       522   \n",
       "\n",
       "                                    Conversation_Prompt  \\\n",
       "0     Good evening Chatgpt,\\nI'd like your help to w...   \n",
       "1     Here is the PLEX readme, I think this will ans...   \n",
       "2     Essencially PLEX loads an openbabel docker con...   \n",
       "3     Excellent work chat, I think we should also ex...   \n",
       "4     Noted,\\nTake a look at this docker file, and t...   \n",
       "...                                                 ...   \n",
       "7971           what would be a good name for this test?   \n",
       "7972  こちらの変更に対して、\\n\\n-    /// 与えられたパスからモデルを取得する\\n+  ...   \n",
       "7973  Here is some rust code:\\n\\n```\\nlet conn =\\n  ...   \n",
       "7974  この2つの処理は一緒でしょうか？\\n\\nconst convertHankakuToZenk...   \n",
       "7975   右クリックなどで開くコンテキストメニューですが、右クリック以外にも開けるような経路はありますか？   \n",
       "\n",
       "                                    Conversation_Answer  \\\n",
       "0     Thanks for sharing the README file for Open Ba...   \n",
       "1     Thanks for sharing the README file for the PLE...   \n",
       "2     Based on the given information, it looks like ...   \n",
       "3     These JSON files are indeed configuration file...   \n",
       "4     This Dockerfile is used to create a Docker ima...   \n",
       "...                                                 ...   \n",
       "7971  ChatGPTA suitable name for this test might be ...   \n",
       "7972  ChatGPTこのディスカッションは、専門的な用語（ここでは「コンストラクト」/「デストラク...   \n",
       "7973  ChatGPTIn the Rust programming language, wheth...   \n",
       "7974  ChatGPTはい、これらの2つの関数は基本的に同じ処理を行っています。両方ともASCIIの...   \n",
       "7975  ChatGPTはい、右クリック以外にもコンテキストメニューを開く方法はいくつかあります。以下...   \n",
       "\n",
       "                                      Detected Patterns  \n",
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "...                                                 ...  \n",
       "7971  Persona Pattern, Recipe Pattern, Output Automa...  \n",
       "7972                                                     \n",
       "7973  Output Automator Pattern, Simple Instruction P...  \n",
       "7974                                                     \n",
       "7975  Output Automator Pattern, Simple Instruction P...  \n",
       "\n",
       "[7976 rows x 25 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99f43c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('pr_sharing_visualize_output_with_patterns.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e902ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
